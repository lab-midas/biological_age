{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/opt/conda/raecker1/envs/nakoukb/lib/python3.9/site-packages/psutil/_psutil_linux.cpython-39-x86_64-linux-gnu.so' could not be imported from '5.9.0 instead of 6.0.0'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keys(keys, output_dir, fname, n_folds=5):\n",
    "    # 80% / 20 % split for train / test\n",
    "    train_set, test_set = train_test_split(keys, test_size=0.2, random_state=42)\n",
    "    train_folds = []\n",
    "    test_folds = []\n",
    "    \"\"\"for train_index, test_index in KFold(n_splits=n_folds).split(keys):\n",
    "        train_folds.append([keys[idx] for idx in train_index])\n",
    "        test_folds.append([keys[idx] for idx in test_index])\"\"\"\n",
    "\n",
    "    with open(output_dir.joinpath('keys', f'train_{fname}.dat'), 'w') as f:\n",
    "        for item in train_set:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open(output_dir.joinpath('keys', f'test_{fname}.dat'), 'w') as f:\n",
    "        for item in test_set:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    \"\"\"for i in range(n_folds):\n",
    "        with open(output_dir.joinpath('keys', 'train{}.dat'.format(i)), 'w') as f:\n",
    "            for item in train_folds[i]:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open(output_dir.joinpath('keys', 'test{}.dat'.format(i)), 'w') as f:\n",
    "            for item in test_folds[i]:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create info ukb_all.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = '/mnt/qdata/share/raecker1/ukbdata_70k/interim/'\n",
    "csv_input = '/mnt/qdata/rawdata/UKBIOBANK/baskets/4053862/ukb677731.csv'\n",
    "csv_input_2 = '/mnt/qdata/rawdata/UKBIOBANK/ukbdata_70k/ukb675384.csv'\n",
    "csv_output = '/mnt/qdata/share/raecker1/ukbdata_70k/interim/ukb_all.csv'\n",
    "\n",
    "\n",
    "\"\"\"df_1 = pd.read_csv(csv_input, usecols=['eid', '21003-2.0', '31-0.0', '21002-0.0', '50-0.0'])\n",
    "#df_1 = pd.read_csv(csv_input, usecols=['eid', '21003-2.0', '21003-1.0', '21003-0.0', '21022-0.0'])\n",
    "df_2 = pd.read_csv(csv_input_2, usecols=['eid', '20201-2.0', '20201-3.0', '20209-2.0', '20209-3.0', '20252-2.0', '20252-3.0'])\n",
    "df = pd.merge(df_2, df_1, how='inner', on='eid')\n",
    "df = df.rename(columns={'eid': 'key', '21003-2.0': 'age', '31-0.0': 'sex', '21002-0.0': 'weight', '50-0.0': 'height'})\"\"\"\n",
    "#df = df.set_index('key')\n",
    "info_df = pd.read_csv(csv_output, index_col=0, usecols=[1,2,3,4,5], dtype={'key': 'string', 'age': np.float32})\n",
    "print('done')\n",
    "#df.to_csv(csv_output, columns=['key', 'age', 'sex', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust for diff between hypothetical and actual imaging data (download, segmentation, conversion errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67597\n",
      "10211\n",
      "9796\n",
      "109\n",
      "9784\n"
     ]
    }
   ],
   "source": [
    "key_file = 'ukb_keys_mainly_healthy_kidney_full.csv'\n",
    "key_file_out = 'ukb_keys_mainly_healthy_kidney.csv'\n",
    "#image_path = '/mnt/qdata/share/raecker1/ukbdata_70k/t1_brain/raw'\n",
    "#image_path = '/mnt/qdata/share/raecker1/ukbdata_70k/sa_heart/processed/seg'\n",
    "organ = 'kidneys'\n",
    "\n",
    "output_dir = Path('/mnt/qdata/rawdata/raecker1/ukbdata_70k/interim/')\n",
    "data_df = pd.DataFrame({'key': [l.strip().split('_')[0] for l in output_dir.joinpath('keys', f'{organ}_imaging.dat').open().readlines()]}, dtype=str)\n",
    "#img_list = os.listdir(image_path)\n",
    "#data_df = pd.DataFrame({'key': [l.split('_')[0] for l in img_list]})\n",
    "print(len(data_df))\n",
    "csv_df = pd.read_csv(os.path.join(output_dir, 'keys', key_file), header=None, names=['key'], dtype=str)\n",
    "print(len(csv_df))\n",
    "df_merged = pd.merge(data_df, csv_df, on='key', how='inner')\n",
    "print(len(df_merged))\n",
    "df_diff_ukb_csvs = pd.read_csv(os.path.join(output_dir, f'images_without_age_label_{organ}.csv'), header=None, names=['key'], dtype=str)\n",
    "print(len(df_diff_ukb_csvs))\n",
    "df_filtered = df_merged[~df_merged['key'].isin(set(df_diff_ukb_csvs['key']))]\n",
    "print(len(df_filtered))\n",
    "df_filtered.to_csv(os.path.join(output_dir, 'keys', key_file_out), index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create train/test keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file = 'ukb_keys_healthy_heart.csv'\n",
    "out_name = 'heart_healthy'\n",
    "\n",
    "output_dir = Path('/mnt/qdata/share/raecker1/ukbdata_70k/interim')\n",
    "keys = pd.read_csv(f'/mnt/qdata/share/raecker1/ukbdata_70k/interim/keys/{key_file}', header=None)\n",
    "keys = keys[0].to_list()\n",
    "create_keys(keys, output_dir, out_name, n_folds=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get full test set keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ = 'heart'\n",
    "output_dir = Path('/mnt/qdata/share/raecker1/ukbdata_70k/interim')\n",
    "#image_path = '/mnt/qdata/share/raecker1/ukbdata_70k/t1_brain/raw'\n",
    "#image_path = '/mnt/qdata/share/raecker1/ukbdata_70k/sa_heart/processed/seg'\n",
    "train_set = '/mnt/qdata/share/raecker1/ukbdata_70k/interim/keys/train_heart_mainly_healthy.dat'\n",
    "fname = 'heart_mainly_healthy'\n",
    "\n",
    "\n",
    "img_df = pd.DataFrame({'key': [l.strip().split('_')[0] for l in output_dir.joinpath('keys', f'{organ}_imaging.dat').open().readlines()]}, dtype=str)                                                 # get all image keys\n",
    "img_wo_age = pd.read_csv(os.path.join(output_dir, f'images_without_age_label_{organ}.csv'), header=None, names=['key'], dtype=str)     # get all image keys without age label\n",
    "train_df = pd.DataFrame({'key': [l.strip() for l in Path(train_set).open().readlines()]})                                           # get all keys in train set\n",
    "\n",
    "df_filtered = img_df[~img_df['key'].isin(set(img_wo_age['key']))]       # filter out images without age label\n",
    "df_out = df_filtered[~df_filtered['key'].isin(set(train_df['key']))]    # filter out images in train set\n",
    "test_key_list = df_out['key'].to_list()\n",
    "\n",
    "with open(output_dir.joinpath('keys', f'full_test_{fname}.dat'), 'w') as f:\n",
    "    for key in test_key_list:\n",
    "        f.write(\"%s\\n\" % key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create csv: images without ages labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3826746/2465348393.py:6: DtypeWarning: Columns (2524) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_2 = pd.read_csv(csv_input_2, usecols=['eid', f'{organ_key}-2.0', f'{organ_key}-3.0'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/raecker1/envs/nakoukb/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/_pydev_imports_tipper.py:205: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "/opt/conda/raecker1/envs/nakoukb/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/_pydev_imports_tipper.py:205: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "/opt/conda/raecker1/envs/nakoukb/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/_pydev_imports_tipper.py:205: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m df_no_age_label \u001b[38;5;241m=\u001b[39m df_merged[(df_merged[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morgan_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-2.0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull() \u001b[38;5;241m|\u001b[39m df_merged[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morgan_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-3.0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()) \u001b[38;5;241m&\u001b[39m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m21003-2.0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_no_age_label))\n\u001b[0;32m---> 14\u001b[0m df_exclude \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mconcat([df_no_age_label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meid\u001b[39m\u001b[38;5;124m'\u001b[39m], df_in_2_notin_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meid\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_exclude))\n\u001b[1;32m     16\u001b[0m df_exclude\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/qdata/share/raecker1/ukbdata_70k/interim/images_without_age_label_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morgan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m df_no_age_label \u001b[38;5;241m=\u001b[39m df_merged[(df_merged[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morgan_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-2.0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull() \u001b[38;5;241m|\u001b[39m df_merged[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morgan_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-3.0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()) \u001b[38;5;241m&\u001b[39m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m21003-2.0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_no_age_label))\n\u001b[0;32m---> 14\u001b[0m df_exclude \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mconcat([df_no_age_label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meid\u001b[39m\u001b[38;5;124m'\u001b[39m], df_in_2_notin_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meid\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_exclude))\n\u001b[1;32m     16\u001b[0m df_exclude\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/qdata/share/raecker1/ukbdata_70k/interim/images_without_age_label_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morgan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/raecker1/envs/nakoukb/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/raecker1/envs/nakoukb/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "organ_key = '20252'\n",
    "organ = 'brain'\n",
    "csv_input = '/mnt/qdata/rawdata/UKBIOBANK/baskets/4053862/ukb677731.csv'\n",
    "csv_input_2 = '/mnt/qdata/rawdata/UKBIOBANK/ukbdata_70k/ukb675384.csv'\n",
    "df_1 = pd.read_csv(csv_input, usecols=['eid', '21003-2.0'])\n",
    "df_2 = pd.read_csv(csv_input_2, usecols=['eid', f'{organ_key}-2.0', f'{organ_key}-3.0'])\n",
    "\n",
    "df_in_2_notin_1 = df_2[~df_2['eid'].isin(df_1['eid'])]\n",
    "print(len(df_in_2_notin_1))\n",
    "\n",
    "df_merged = pd.merge(df_1, df_2, on='eid', how='inner')\n",
    "df_no_age_label = df_merged[(df_merged[f'{organ_key}-2.0'].notnull() | df_merged[f'{organ_key}-3.0'].notnull()) & df_merged['21003-2.0'].isnull()]\n",
    "print(len(df_no_age_label))\n",
    "df_exclude = pd.concat([df_no_age_label['eid'], df_in_2_notin_1['eid']]).drop_duplicates()\n",
    "print(len(df_exclude))\n",
    "df_exclude.to_csv(f'/mnt/qdata/share/raecker1/ukbdata_70k/interim/images_without_age_label_{organ}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('/mnt/qdata/rawdata/UKBIOBANK/baskets/4053862/ukb677731.csv', usecols=['eid'])\n",
    "df_2 = pd.read_csv('', usecols=['eid'])\n",
    "\n",
    "organ = 'brain'\n",
    "output_dir = Path('/mnt/qdata/share/raecker1/ukbdata_70k/interim')\n",
    "#image_path = '/mnt/qdata/share/raecker1/ukbdata_70k/t1_brain/raw'\n",
    "#image_path = '/mnt/qdata/share/raecker1/ukbdata_70k/sa_heart/processed/seg'\n",
    "train_set = '/mnt/qdata/share/raecker1/ukbdata_70k/interim/keys/train_brain_healthy.dat'\n",
    "fname = 'brain_healthy'\n",
    "\n",
    "\n",
    "img_df = pd.DataFrame({'key': [l.strip().split('_')[0] for l in output_dir.joinpath('keys', f'{organ}_imaging.dat').open().readlines()]}, dtype=str)                                                 # get all image keys\n",
    "img_wo_age = pd.read_csv(os.path.join(output_dir, f'images_without_age_label_{organ}.csv'), header=None, names=['key'], dtype=str)     # get all image keys without age label\n",
    "train_df = pd.DataFrame({'key': [l.strip() for l in Path(train_set).open().readlines()]})                                           # get all keys in train set\n",
    "\n",
    "df_filtered = img_df[~img_df['key'].isin(set(img_wo_age['key']))]       # filter out images without age label\n",
    "df_out = df_filtered[~df_filtered['key'].isin(set(train_df['key']))]    # filter out images in train set\n",
    "test_key_list = df_out['key'].to_list()\n",
    "\n",
    "with open(output_dir.joinpath('keys', f'full_test_{fname}.dat'), 'w') as f:\n",
    "    for key in test_key_list:\n",
    "        f.write(\"%s\\n\" % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path('/mnt/qdata/share/raecker1/ukbdata_70k/interim/')\n",
    "data = '/mnt/qdata/share/raecker1/ukbdata_70k/interim/ukb_heart_preprocessed.h5'\n",
    "fhandle = h5py.File(data, 'r')\n",
    "group = fhandle['image']\n",
    "keys = group.keys()\n",
    "print('done')\n",
    "with open(output_dir.joinpath('keys', 'heart_imaging.dat'), 'w') as f:\n",
    "    for key in keys:\n",
    "        f.write(\"%s\\n\" % key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nakoukb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
