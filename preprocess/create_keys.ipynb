{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/opt/conda/raecker1/envs/nakoukb/lib/python3.9/site-packages/psutil/_psutil_linux.cpython-39-x86_64-linux-gnu.so' could not be imported from '5.9.0 instead of 6.0.0'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keys(keys, output_dir, fname, n_folds=5):\n",
    "    # 80% / 20 % split for train / test\n",
    "    train_set, test_set = train_test_split(keys, test_size=0.2, random_state=42)\n",
    "    train_folds = []\n",
    "    test_folds = []\n",
    "    \"\"\"for train_index, test_index in KFold(n_splits=n_folds).split(keys):\n",
    "        train_folds.append([keys[idx] for idx in train_index])\n",
    "        test_folds.append([keys[idx] for idx in test_index])\"\"\"\n",
    "\n",
    "    with open(output_dir.joinpath('keys', f'train_{fname}.dat'), 'w') as f:\n",
    "        for item in train_set:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open(output_dir.joinpath('keys', f'test_{fname}.dat'), 'w') as f:\n",
    "        for item in test_set:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    \"\"\"for i in range(n_folds):\n",
    "        with open(output_dir.joinpath('keys', 'train{}.dat'.format(i)), 'w') as f:\n",
    "            for item in train_folds[i]:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open(output_dir.joinpath('keys', 'test{}.dat'.format(i)), 'w') as f:\n",
    "            for item in test_folds[i]:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create info ukb_all.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = '/mnt/qdata/share/raecker1/ukbdata_70k/interim/'\n",
    "csv_input = '/mnt/qdata/rawdata/UKBIOBANK/baskets/4053862/ukb677731.csv'\n",
    "csv_input_2 = '/mnt/qdata/rawdata/UKBIOBANK/ukbdata_70k/ukb675384.csv'\n",
    "csv_output = '/mnt/qdata/share/raecker1/ukbdata_70k/interim/ukb_all.csv'\n",
    "\n",
    "\n",
    "\"\"\"df_1 = pd.read_csv(csv_input, usecols=['eid', '21003-2.0', '31-0.0', '21002-0.0', '50-0.0'])\n",
    "#df_1 = pd.read_csv(csv_input, usecols=['eid', '21003-2.0', '21003-1.0', '21003-0.0', '21022-0.0'])\n",
    "df_2 = pd.read_csv(csv_input_2, usecols=['eid', '20201-2.0', '20201-3.0', '20209-2.0', '20209-3.0', '20252-2.0', '20252-3.0'])\n",
    "df = pd.merge(df_2, df_1, how='inner', on='eid')\n",
    "df = df.rename(columns={'eid': 'key', '21003-2.0': 'age', '31-0.0': 'sex', '21002-0.0': 'weight', '50-0.0': 'height'})\"\"\"\n",
    "#df = df.set_index('key')\n",
    "info_df = pd.read_csv(csv_output, index_col=0, usecols=[1,2,3,4,5], dtype={'key': 'string', 'age': np.float32})\n",
    "print('done')\n",
    "#df.to_csv(csv_output, columns=['key', 'age', 'sex', 'weight', 'height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust for diff between hypothetical and actual imaging data (download, segmentation, conversion errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46333\n",
      "47199\n",
      "29660\n",
      "153\n",
      "29648\n"
     ]
    }
   ],
   "source": [
    "key_file = 'ukb_keys_mainly_healthy_heart_full.csv'\n",
    "key_file_out = 'ukb_keys_mainly_healthy_heart.csv'\n",
    "\n",
    "output_dir = Path('/mnt/qdata/share/raecker1/ukbdata_70k/interim/')\n",
    "data_df = pd.DataFrame({'key': [l.strip() for l in output_dir.joinpath('keys', 'heart_imaging.dat').open().readlines()]}, dtype=str)\n",
    "print(len(data_df))\n",
    "csv_df = pd.read_csv(os.path.join(output_dir, 'keys', key_file), header=None, names=['key'], dtype=str)\n",
    "print(len(csv_df))\n",
    "df_merged = pd.merge(data_df, csv_df, on='key', how='inner')\n",
    "print(len(df_merged))\n",
    "df_diff_ukb_csvs = pd.read_csv(os.path.join(output_dir, 'images_without_age_label.csv'), header=None, names=['key'], dtype=str)\n",
    "print(len(df_diff_ukb_csvs))\n",
    "df_filtered = df_merged[~df_merged['key'].isin(set(df_diff_ukb_csvs['key']))]\n",
    "print(len(df_filtered))\n",
    "df_filtered.to_csv(os.path.join(output_dir, 'keys', key_file_out), index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create train/test keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file = 'ukb_keys_mainly_healthy_heart.csv'\n",
    "out_name = 'heart_mainly_healthy'\n",
    "\n",
    "output_dir = Path('/mnt/qdata/share/raecker1/ukbdata_70k/interim')\n",
    "keys = pd.read_csv(f'/mnt/qdata/share/raecker1/ukbdata_70k/interim/keys/{key_file}', header=None)\n",
    "keys = keys[0].to_list()\n",
    "create_keys(keys, output_dir, out_name, n_folds=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nakoukb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
